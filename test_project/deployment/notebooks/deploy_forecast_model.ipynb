{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##################################################################################\n",
        "# Model Deployment Notebook\n",
        "#\n",
        "# This notebook deploys a validated Prophet forecasting model to a Model Serving\n",
        "# endpoint and optionally promotes it to the \"champion\" alias.\n",
        "#\n",
        "# Parameters:\n",
        "#\n",
        "# * env                        - Environment (dev, staging, prod)\n",
        "# * model_name                 - Three-level UC model name\n",
        "# * model_version              - Model version to deploy (optional, defaults to \"challenger\")\n",
        "# * serving_endpoint_name      - Name for the serving endpoint\n",
        "# * promote_to_champion        - Whether to promote model to champion alias (true/false)\n",
        "# * test_endpoint              - Whether to test the endpoint after deployment (true/false)\n",
        "# * endpoint_config_json       - Optional JSON config for endpoint (defaults provided)\n",
        "##################################################################################\n",
        "\n",
        "# MAGIC %load_ext autoreload\n",
        "# MAGIC %autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Install dependencies\n",
        "# MAGIC %pip install prophet databricks-sdk mlflow pandas requests\n",
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Notebook arguments\n",
        "dbutils.widgets.text(\"env\", \"dev\", \"Environment\")\n",
        "dbutils.widgets.text(\"model_name\", \"johannes_oehler.vectorlab.prophet_forecast\", \"Model Name\")\n",
        "dbutils.widgets.text(\"model_version\", \"\", \"Model Version (leave empty to use 'challenger')\")\n",
        "dbutils.widgets.text(\"serving_endpoint_name\", \"forecast_joe\", \"Serving Endpoint Name\")\n",
        "dbutils.widgets.dropdown(\"promote_to_champion\", \"true\", [\"true\", \"false\"], \"Promote to Champion\")\n",
        "dbutils.widgets.dropdown(\"test_endpoint\", \"true\", [\"true\", \"false\"], \"Test Endpoint After Deployment\")\n",
        "dbutils.widgets.text(\"endpoint_config_json\", \"\", \"Endpoint Config JSON (optional)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Get parameters\n",
        "import mlflow\n",
        "from mlflow.tracking.client import MlflowClient\n",
        "\n",
        "# Setup MLflow\n",
        "client = MlflowClient(registry_uri=\"databricks-uc\")\n",
        "mlflow.set_registry_uri('databricks-uc')\n",
        "\n",
        "# Get parameters\n",
        "env = dbutils.widgets.get(\"env\")\n",
        "model_name = dbutils.widgets.get(\"model_name\")\n",
        "serving_endpoint_name = dbutils.widgets.get(\"serving_endpoint_name\")\n",
        "promote_to_champion = dbutils.widgets.get(\"promote_to_champion\").lower() == \"true\"\n",
        "test_endpoint = dbutils.widgets.get(\"test_endpoint\").lower() == \"true\"\n",
        "endpoint_config_json = dbutils.widgets.get(\"endpoint_config_json\")\n",
        "\n",
        "# Get model version from task values or widget\n",
        "model_version = dbutils.jobs.taskValues.get(\"Train\", \"model_version\", debugValue=\"\")\n",
        "if model_version == \"\":\n",
        "    model_version = dbutils.widgets.get(\"model_version\")\n",
        "\n",
        "# If no version specified, use the \"challenger\" alias\n",
        "if model_version == \"\":\n",
        "    print(\"No model version specified. Using 'challenger' alias...\")\n",
        "    try:\n",
        "        challenger_model = client.get_model_version_by_alias(model_name, \"challenger\")\n",
        "        model_version = challenger_model.version\n",
        "        print(f\"Found challenger model version: {model_version}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Could not find 'challenger' alias for model {model_name}\")\n",
        "        print(f\"Details: {e}\")\n",
        "        raise ValueError(\"No model version specified and no 'challenger' alias found. Please specify a model version.\")\n",
        "\n",
        "model_uri = f\"models:/{model_name}/{model_version}\"\n",
        "\n",
        "print(\"\\n=== Deployment Configuration ===\")\n",
        "print(f\"Environment: {env}\")\n",
        "print(f\"Model Name: {model_name}\")\n",
        "print(f\"Model Version: {model_version}\")\n",
        "print(f\"Model URI: {model_uri}\")\n",
        "print(f\"Endpoint Name: {serving_endpoint_name}\")\n",
        "print(f\"Promote to Champion: {promote_to_champion}\")\n",
        "print(f\"Test Endpoint: {test_endpoint}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Setup Databricks SDK\n",
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service.serving import (\n",
        "    EndpointCoreConfigInput,\n",
        "    ServedEntityInput,\n",
        "    AutoCaptureConfigInput,\n",
        ")\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Initialize Workspace Client\n",
        "w = WorkspaceClient()\n",
        "\n",
        "print(\"Databricks Workspace Client initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Check if endpoint exists\n",
        "def endpoint_exists(endpoint_name):\n",
        "    \"\"\"Check if a serving endpoint already exists.\"\"\"\n",
        "    try:\n",
        "        w.serving_endpoints.get(endpoint_name)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def wait_for_endpoint_ready(endpoint_name, timeout_seconds=1800):\n",
        "    \"\"\"Wait for endpoint to be in READY state.\"\"\"\n",
        "    from databricks.sdk.service.serving import EndpointStateConfigUpdate, EndpointStateReady\n",
        "    \n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < timeout_seconds:\n",
        "        endpoint = w.serving_endpoints.get(endpoint_name)\n",
        "        state = endpoint.state.config_update if endpoint.state else None\n",
        "        ready = endpoint.state.ready if endpoint.state else None\n",
        "        \n",
        "        # Check if endpoint is ready (compare enum values, not strings)\n",
        "        if state == EndpointStateConfigUpdate.NOT_UPDATING and ready == EndpointStateReady.READY:\n",
        "            print(f\"✓ Endpoint '{endpoint_name}' is READY\")\n",
        "            return True\n",
        "        elif state == EndpointStateConfigUpdate.UPDATE_FAILED:\n",
        "            print(f\"✗ Endpoint '{endpoint_name}' update FAILED\")\n",
        "            return False\n",
        "        \n",
        "        print(f\"  Waiting for endpoint... State: {state}, Ready: {ready}\")\n",
        "        time.sleep(30)\n",
        "    \n",
        "    print(f\"✗ Timeout waiting for endpoint '{endpoint_name}' to be ready\")\n",
        "    return False\n",
        "\n",
        "\n",
        "endpoint_already_exists = endpoint_exists(serving_endpoint_name)\n",
        "print(f\"Endpoint '{serving_endpoint_name}' exists: {endpoint_already_exists}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Prepare endpoint configuration\n",
        "# Parse custom endpoint config if provided, otherwise use defaults\n",
        "if endpoint_config_json and endpoint_config_json.strip():\n",
        "    try:\n",
        "        endpoint_config = json.loads(endpoint_config_json)\n",
        "        print(\"Using custom endpoint configuration\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing endpoint_config_json: {e}\")\n",
        "        print(\"Falling back to default configuration\")\n",
        "        endpoint_config = {}\n",
        "else:\n",
        "    endpoint_config = {}\n",
        "\n",
        "# Build served entity configuration\n",
        "served_entity = ServedEntityInput(\n",
        "    entity_name=model_name,\n",
        "    entity_version=model_version,\n",
        "    scale_to_zero_enabled=endpoint_config.get(\"scale_to_zero_enabled\", True),\n",
        "    workload_size=endpoint_config.get(\"workload_size\", \"Small\"),\n",
        "    workload_type=endpoint_config.get(\"workload_type\", \"CPU\"),\n",
        ")\n",
        "\n",
        "# Enable inference table logging for monitoring\n",
        "auto_capture_config = AutoCaptureConfigInput(\n",
        "    catalog_name=model_name.split(\".\")[0],  # Extract catalog from model name\n",
        "    schema_name=model_name.split(\".\")[1],   # Extract schema from model name\n",
        "    table_name_prefix=serving_endpoint_name,\n",
        "    enabled=endpoint_config.get(\"auto_capture_enabled\", True),\n",
        ")\n",
        "\n",
        "print(\"\\n=== Endpoint Configuration ===\")\n",
        "print(f\"Scale to Zero: {served_entity.scale_to_zero_enabled}\")\n",
        "print(f\"Workload Size: {served_entity.workload_size}\")\n",
        "print(f\"Workload Type: {served_entity.workload_type}\")\n",
        "print(f\"Auto Capture Enabled: {auto_capture_config.enabled}\")\n",
        "print(f\"Inference Table: {auto_capture_config.catalog_name}.{auto_capture_config.schema_name}.{auto_capture_config.table_name_prefix}_*\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Create or update serving endpoint\n",
        "print(f\"\\n{'='*60}\")\n",
        "if endpoint_already_exists:\n",
        "    print(f\"Updating existing endpoint: {serving_endpoint_name}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    # Update existing endpoint\n",
        "    w.serving_endpoints.update_config(\n",
        "        name=serving_endpoint_name,\n",
        "        served_entities=[served_entity],\n",
        "        auto_capture_config=auto_capture_config,\n",
        "    )\n",
        "    print(f\"✓ Update initiated for endpoint '{serving_endpoint_name}'\")\n",
        "else:\n",
        "    print(f\"Creating new endpoint: {serving_endpoint_name}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    # Create new endpoint\n",
        "    w.serving_endpoints.create(\n",
        "        name=serving_endpoint_name,\n",
        "        config=EndpointCoreConfigInput(\n",
        "            served_entities=[served_entity],\n",
        "            auto_capture_config=auto_capture_config,\n",
        "        ),\n",
        "    )\n",
        "    print(f\"✓ Creation initiated for endpoint '{serving_endpoint_name}'\")\n",
        "\n",
        "# Wait for endpoint to be ready\n",
        "print(\"\\nWaiting for endpoint to be ready...\")\n",
        "if not wait_for_endpoint_ready(serving_endpoint_name):\n",
        "    raise Exception(f\"Endpoint '{serving_endpoint_name}' failed to become ready\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"✓ Endpoint '{serving_endpoint_name}' is now ready and serving model version {model_version}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Promote model to champion (optional)\n",
        "if promote_to_champion:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Promoting model version {model_version} to 'champion' alias\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    try:\n",
        "        # Check if champion alias already exists\n",
        "        try:\n",
        "            current_champion = client.get_model_version_by_alias(model_name, \"champion\")\n",
        "            print(f\"Current champion version: {current_champion.version}\")\n",
        "        except Exception:\n",
        "            print(\"No current champion version found\")\n",
        "        \n",
        "        # Set the new champion\n",
        "        client.set_registered_model_alias(model_name, \"champion\", model_version)\n",
        "        print(f\"✓ Model version {model_version} promoted to 'champion' alias\")\n",
        "        \n",
        "        # Update model description\n",
        "        model_version_details = client.get_model_version(model_name, model_version)\n",
        "        current_description = model_version_details.description or \"\"\n",
        "        \n",
        "        deployment_info = f\"\\n\\n---\\n\\nPromotion to Champion: SUCCESS\\nEnvironment: {env}\\nEndpoint: {serving_endpoint_name}\\nTimestamp: {time.strftime('%Y-%m-%d %H:%M:%S UTC', time.gmtime())}\"\n",
        "        \n",
        "        client.update_model_version(\n",
        "            name=model_name,\n",
        "            version=model_version,\n",
        "            description=current_description + deployment_info\n",
        "        )\n",
        "        print(\"✓ Model description updated with deployment information\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error promoting model to champion: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"\\nSkipping promotion to champion (promote_to_champion=false)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Test the deployed endpoint (optional)\n",
        "if test_endpoint:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Testing deployed endpoint\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    import pandas as pd\n",
        "    from datetime import datetime, timedelta\n",
        "    \n",
        "    # Create sample test data\n",
        "    # For Prophet model, we need historical data points with 'ds' and 'y' columns\n",
        "    end_date = datetime.now().date()\n",
        "    start_date = end_date - timedelta(days=30)\n",
        "    \n",
        "    test_data = pd.DataFrame({\n",
        "        'ds': pd.date_range(start=start_date, end=end_date, freq='D'),\n",
        "        'y': [100 + i * 2 + (i % 7) * 5 for i in range(31)]  # Synthetic data with trend and weekly pattern\n",
        "    })\n",
        "    \n",
        "    print(\"Sample input data:\")\n",
        "    print(test_data.head())\n",
        "    print(f\"\\nTotal records: {len(test_data)}\")\n",
        "    \n",
        "    try:\n",
        "        # Query the endpoint\n",
        "        print(\"\\nQuerying endpoint...\")\n",
        "        \n",
        "        # Convert dataframe to the format expected by the endpoint\n",
        "        dataframe_records = test_data.to_dict(orient='split')\n",
        "        \n",
        "        response = w.serving_endpoints.query(\n",
        "            name=serving_endpoint_name,\n",
        "            dataframe_records=dataframe_records,\n",
        "        )\n",
        "        \n",
        "        print(\"\\n✓ Endpoint test successful!\")\n",
        "        print(\"\\nSample predictions:\")\n",
        "        \n",
        "        # Parse and display predictions\n",
        "        if hasattr(response, 'predictions'):\n",
        "            predictions_df = pd.DataFrame(response.predictions)\n",
        "            print(predictions_df.head(10))\n",
        "            print(f\"\\nTotal forecast points: {len(predictions_df)}\")\n",
        "        else:\n",
        "            print(response)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Endpoint test failed: {e}\")\n",
        "        print(\"\\nNote: The endpoint is deployed but the test query failed.\")\n",
        "        print(\"This might be due to the specific input format expected by your model.\")\n",
        "        print(\"Please verify the endpoint manually or adjust the test data format.\")\n",
        "else:\n",
        "    print(\"\\nSkipping endpoint testing (test_endpoint=false)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBTITLE 1, Set task values and return deployment info\n",
        "# Get endpoint details\n",
        "endpoint = w.serving_endpoints.get(serving_endpoint_name)\n",
        "endpoint_url = f\"{w.config.host}/serving-endpoints/{serving_endpoint_name}/invocations\"\n",
        "\n",
        "deployment_info = {\n",
        "    \"endpoint_name\": serving_endpoint_name,\n",
        "    \"endpoint_url\": endpoint_url,\n",
        "    \"model_name\": model_name,\n",
        "    \"model_version\": model_version,\n",
        "    \"model_uri\": model_uri,\n",
        "    \"promoted_to_champion\": promote_to_champion,\n",
        "    \"environment\": env,\n",
        "}\n",
        "\n",
        "# Set task values for downstream tasks\n",
        "dbutils.jobs.taskValues.set(\"endpoint_name\", serving_endpoint_name)\n",
        "dbutils.jobs.taskValues.set(\"endpoint_url\", endpoint_url)\n",
        "dbutils.jobs.taskValues.set(\"model_version_deployed\", model_version)\n",
        "dbutils.jobs.taskValues.set(\"champion_promoted\", str(promote_to_champion))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"DEPLOYMENT SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Endpoint Name: {serving_endpoint_name}\")\n",
        "print(f\"Endpoint URL: {endpoint_url}\")\n",
        "print(f\"Model: {model_name} (version {model_version})\")\n",
        "print(f\"Model URI: {model_uri}\")\n",
        "print(f\"Promoted to Champion: {promote_to_champion}\")\n",
        "print(f\"Environment: {env}\")\n",
        "print(f\"Status: ✓ DEPLOYED SUCCESSFULLY\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Exit with deployment info JSON\n",
        "import json\n",
        "dbutils.notebook.exit(json.dumps(deployment_info))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
